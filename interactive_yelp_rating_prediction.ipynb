{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Yelp Rating Prediction Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides an interactive, educational experience for understanding and running the complete Yelp star rating prediction pipeline. We'll walk through each stage of the machine learning process, from data loading to model inference, with hands-on visualizations and parameter tuning.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the Yelp Academic Dataset structure\n",
    "- Learn data preprocessing and feature engineering techniques\n",
    "- Explore sentiment analysis using transformer models\n",
    "- Perform feature selection and model training\n",
    "- Evaluate model performance and make predictions\n",
    "\n",
    "### Pipeline Stages\n",
    "1. **Data Loading & Preprocessing**: Load and clean raw Yelp data\n",
    "2. **Feature Engineering**: Create derived features from raw data\n",
    "3. **Sentiment Analysis**: Extract sentiment scores from review text\n",
    "4. **Feature Selection**: Identify optimal feature subset\n",
    "5. **Model Training**: Train neural network for rating prediction\n",
    "6. **Inference**: Make predictions on new data\n",
    "7. **Analysis**: Deep dive into results and insights\n",
    "\n",
    "### Dataset\n",
    "We'll use the Yelp Academic Dataset, which includes:\n",
    "- **Business data**: Restaurant information and ratings\n",
    "- **Review data**: User reviews with text and ratings\n",
    "- **User data**: Reviewer profiles and history\n",
    "\n",
    "The goal is to predict the star rating (1-5) a user would give to a business based on user and business characteristics, plus review sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction and Setup\n",
    "\n",
    "### Learning Objectives\n",
    "- Set up the Python environment\n",
    "- Verify GPU availability\n",
    "- Understand configuration parameters\n",
    "- Load required libraries and modules\n",
    "\n",
    "### Environment Requirements\n",
    "- Python 3.8+\n",
    "- PyTorch with MPS/CUDA support\n",
    "- Transformers library\n",
    "- Jupyter widgets for interactivity\n",
    "\n",
    "Let's start by setting up our environment and verifying everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup and imports\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path for local imports\n",
    "sys.path.append('src')\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Import machine learning libraries\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Import pipeline modules\n",
    "from src.preprocessing import preprocess_pipeline\n",
    "from src.features import feature_engineering_pipeline\n",
    "from src.sentiment import sentiment_analysis_pipeline\n",
    "from src.feature_selection import feature_selection_pipeline\n",
    "from src.train import training_pipeline\n",
    "from src import config\n",
    "import src.utils as utils\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU detection and device setup\n",
    "device_info = utils.verify_gpu_support()\n",
    "print(f\"GPU Support: {device_info}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "utils.set_seed(config.SEED)\n",
    "print(f\"✓ Random seed set to: {config.SEED}\")\n",
    "\n",
    "# Display configuration\n",
    "print(\"\\n=== CONFIGURATION ===\")\n",
    "print(f\"Data Directory: {config.DATA_DIR}\")\n",
    "print(f\"Learning Rate: {config.LEARNING_RATE}\")\n",
    "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"Max Epochs: {config.MAX_EPOCHS}\")\n",
    "print(f\"Sentiment Model: {config.MODEL_NAME}\")\n",
    "print(f\"Candidate Features: {config.CANDIDATE_FEATURES}\")\n",
    "print(\"=====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive: Environment Verification\n",
    "\n",
    "Let's verify that all our data files exist and check their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files exist\n",
    "print(\"Checking data file availability:\")\n",
    "for name, path in config.INPUT_FILES.items():\n",
    "    exists = os.path.exists(path)\n",
    "    size_mb = os.path.getsize(path) / (1024**2) if exists else 0\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {name.capitalize()} data: {path} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Check output directories\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "print(\"\\n✓ Output directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Loading and Preprocessing\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the structure of the Yelp dataset\n",
    "- Learn data loading and merging techniques\n",
    "- Handle missing values and data cleaning\n",
    "- Visualize data distributions and relationships\n",
    "\n",
    "### What We'll Do\n",
    "1. Load the three main datasets (business, review, user)\n",
    "2. Rename columns to avoid conflicts\n",
    "3. Convert date columns to datetime format\n",
    "4. Merge datasets using inner joins\n",
    "5. Clean data by removing rows with missing critical values\n",
    "6. Explore the merged dataset\n",
    "\n",
    "This preprocessing step transforms raw CSV files into a clean, merged dataset ready for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the preprocessing pipeline\n",
    "print(\"Starting data preprocessing pipeline...\")\n",
    "print(\"This may take a few minutes depending on your system.\")\n",
    "\n",
    "try:\n",
    "    merged_df = preprocess_pipeline()\n",
    "    print(\"\\n✓ Preprocessing completed successfully!\")\n",
    "    print(f\"Final dataset shape: {merged_df.shape}\")\n",
    "    print(f\"Memory usage: {merged_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during preprocessing: {e}\")\n",
    "    print(\"Please check your data files and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\" * 50)\n",
    "print(merged_df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(merged_df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(merged_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Data Distributions After Preprocessing', fontsize=16)\n",
    "\n",
    "# Stars distribution\n",
    "merged_df['stars'].value_counts().sort_index().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Star Ratings Distribution')\n",
    "axes[0,0].set_xlabel('Stars')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# User average stars\n",
    "merged_df['user_average_stars'].hist(bins=20, ax=axes[0,1])\n",
    "axes[0,1].set_title('User Average Stars')\n",
    "axes[0,1].set_xlabel('Average Stars')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Business average stars\n",
    "merged_df['business_average_stars'].hist(bins=20, ax=axes[0,2])\n",
    "axes[0,2].set_title('Business Average Stars')\n",
    "axes[0,2].set_xlabel('Average Stars')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "\n",
    "# User review count\n",
    "merged_df['user_review_count'].hist(bins=50, ax=axes[1,0], range=(0, merged_df['user_review_count'].quantile(0.95)))\n",
    "axes[1,0].set_title('User Review Count (95th percentile)')\n",
    "axes[1,0].set_xlabel('Review Count')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "\n",
    "# Business review count\n",
    "merged_df['business_review_count'].hist(bins=50, ax=axes[1,1], range=(0, merged_df['business_review_count'].quantile(0.95)))\n",
    "axes[1,1].set_title('Business Review Count (95th percentile)')\n",
    "axes[1,1].set_xlabel('Review Count')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "# Review year distribution\n",
    "merged_df['date'].dt.year.value_counts().sort_index().plot(kind='bar', ax=axes[1,2])\n",
    "axes[1,2].set_title('Reviews by Year')\n",
    "axes[1,2].set_xlabel('Year')\n",
    "axes[1,2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = merged_df.isnull().sum()\n",
    "missing_percent = (missing_data / len(merged_df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "display(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_data.sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_data[missing_data > 0].sort_values(ascending=True).plot(kind='barh')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Number of Missing Values')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✓ No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Feature Engineering\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand feature engineering concepts\n",
    "- Create time-based features\n",
    "- Engineer elite status features\n",
    "- Handle missing values appropriately\n",
    "- Visualize feature distributions and correlations\n",
    "\n",
    "### What We'll Do\n",
    "1. **Time Features**: Calculate `time_yelping` (weeks since user joined)\n",
    "2. **Elite Features**: Count total elite statuses and check current elite status\n",
    "3. **Missing Value Handling**: Impute missing values with appropriate strategies\n",
    "4. **Feature Analysis**: Explore correlations and distributions\n",
    "\n",
    "Feature engineering transforms raw data into meaningful predictors that capture the underlying patterns in user behavior and business characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature engineering pipeline\n",
    "print(\"Starting feature engineering pipeline...\")\n",
    "\n",
    "try:\n",
    "    featured_df = feature_engineering_pipeline(merged_df)\n",
    "    print(\"\\n✓ Feature engineering completed successfully!\")\n",
    "    \n",
    "    # Show new features added\n",
    "    new_features = [col for col in featured_df.columns if col not in merged_df.columns]\n",
    "    print(f\"\\nAdded {len(new_features)} new features:\")\n",
    "    for i, feature in enumerate(new_features, 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during feature engineering: {e}\")\n",
    "    print(\"Please check the previous steps and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature engineering results\n",
    "print(\"Feature Engineering Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original features: {len(merged_df.columns)}\")\n",
    "print(f\"Engineered features: {len(featured_df.columns)}\")\n",
    "print(f\"New features added: {len(featured_df.columns) - len(merged_df.columns)}\")\n",
    "\n",
    "# Show statistics for new features\n",
    "print(\"\\nNew Feature Statistics:\")\n",
    "display(featured_df[new_features].describe())\n",
    "\n",
    "# Show sample of engineered data\n",
    "print(\"\\nSample of Engineered Data:\")\n",
    "display(featured_df[['stars', 'user_average_stars', 'business_average_stars', 'time_yelping', 'elite_status', 'total_elite_statuses']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize engineered features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Engineered Feature Distributions', fontsize=16)\n",
    "\n",
    "# Time yelping distribution\n",
    "featured_df['time_yelping'].hist(bins=50, ax=axes[0,0])\n",
    "axes[0,0].set_title('Time Yelping (weeks)')\n",
    "axes[0,0].set_xlabel('Weeks')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Elite status distribution\n",
    "featured_df['elite_status'].value_counts().sort_index().plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Elite Status Distribution')\n",
    "axes[0,1].set_xlabel('Elite Status (0=No, 1=Yes)')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "\n",
    "# Total elite statuses\n",
    "featured_df['total_elite_statuses'].value_counts().sort_index().plot(kind='bar', ax=axes[0,2])\n",
    "axes[0,2].set_title('Total Elite Statuses')\n",
    "axes[0,2].set_xlabel('Number of Elite Years')\n",
    "axes[0,2].set_ylabel('Count')\n",
    "\n",
    "# Date year distribution\n",
    "featured_df['date_year'].value_counts().sort_index().plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Reviews by Year')\n",
    "axes[1,0].set_xlabel('Year')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "\n",
    "# Correlation heatmap for key features\n",
    "corr_features = ['stars', 'user_average_stars', 'business_average_stars', 'time_yelping', 'elite_status', 'total_elite_statuses']\n",
    "corr_matrix = featured_df[corr_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=axes[1,1])\n",
    "axes[1,1].set_title('Feature Correlations')\n",
    "\n",
    "# Scatter plot: time_yelping vs stars\n",
    "axes[1,2].scatter(featured_df['time_yelping'], featured_df['stars'], alpha=0.1)\n",
    "axes[1,2].set_title('Time Yelping vs Star Rating')\n",
    "axes[1,2].set_xlabel('Time Yelping (weeks)')\n",
    "axes[1,2].set_ylabel('Stars')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive: Feature Importance Preview\n",
    "\n",
    "Let's explore which features might be most predictive of the star rating using a simple correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation with target\n",
    "target_correlations = featured_df.corr()['stars'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature Correlations with Target (Stars):\")\n",
    "print(\"=\" * 50)\n",
    "for feature, corr in target_correlations.items():\n",
    "    if feature != 'stars':\n",
    "        print(f\"{feature:25s}: {corr:.4f}\")\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = target_correlations.head(15).index[1:]  # Exclude 'stars' itself\n",
    "top_corrs = target_correlations.head(15).values[1:]\n",
    "\n",
    "bars = plt.barh(range(len(top_features)), top_corrs)\n",
    "plt.yticks(range(len(top_features)), top_features)\n",
    "plt.xlabel('Absolute Correlation with Stars')\n",
    "plt.title('Top Feature Correlations with Target')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Color bars by correlation strength\n",
    "for i, (bar, corr) in enumerate(zip(bars, top_corrs)):\n",
    "    if corr > 0.3:\n",
    "        bar.set_color('darkred')\n",
    "    elif corr > 0.2:\n",
    "        bar.set_color('red')\n",
    "    elif corr > 0.1:\n",
    "        bar.set_color('orange')\n",
    "    else:\n",
    "        bar.set_color('lightblue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Sentiment Analysis\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand sentiment analysis with transformers\n",
    "- Learn text preprocessing techniques\n",
    "- Explore sentiment score distributions\n",
    "- Analyze sentiment vs rating relationships\n",
    "\n",
    "### What We'll Do\n",
    "1. **Text Preprocessing**: Smart truncation to handle long reviews\n",
    "2. **Model Loading**: Initialize DistilBERT sentiment classifier\n",
    "3. **Batch Processing**: Process reviews in batches with progress tracking\n",
    "4. **Score Normalization**: Convert to [-1, 1] scale\n",
    "5. **Analysis**: Explore sentiment patterns and correlations\n",
    "\n",
    "Sentiment analysis extracts emotional tone from review text, providing a quantitative measure of user satisfaction beyond star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sentiment analysis pipeline\n",
    "print(\"Starting sentiment analysis pipeline...\")\n",
    "print(\"This will take considerable time (10-30 minutes) depending on your hardware.\")\n",
    "print(\"The progress bar will show the processing status.\")\n",
    "\n",
    "try:\n",
    "    sentiment_df = sentiment_analysis_pipeline(featured_df)\n",
    "    print(\"\\n✓ Sentiment analysis completed successfully!\")\n",
    "    \n",
    "    # Show sentiment columns added\n",
    "    sentiment_cols = ['sentiment_label', 'sentiment_score_raw', 'normalized_sentiment_score']\n",
    "    print(f\"\\nAdded sentiment columns: {sentiment_cols}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during sentiment analysis: {e}\")\n",
    "    print(\"This step requires significant computational resources.\")\n",
    "    print(\"Consider using a machine with GPU support for faster processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sentiment analysis results\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "display(sentiment_df[sentiment_cols].describe())\n",
    "\n",
    "# Show sample with sentiment\n",
    "print(\"\\nSample Reviews with Sentiment:\")\n",
    "sample_cols = ['text', 'stars', 'sentiment_label', 'normalized_sentiment_score']\n",
    "display(sentiment_df[sample_cols].head())\n",
    "\n",
    "# Sentiment label distribution\n",
    "print(\"\\nSentiment Label Distribution:\")\n",
    "print(sentiment_df['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Sentiment Analysis Visualizations', fontsize=16)\n",
    "\n",
    "# Sentiment score distribution\n",
    "sentiment_df['normalized_sentiment_score'].hist(bins=50, ax=axes[0,0], alpha=0.7)\n",
    "axes[0,0].set_title('Normalized Sentiment Score Distribution')\n",
    "axes[0,0].set_xlabel('Sentiment Score')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(0, color='red', linestyle='--', alpha=0.7, label='Neutral')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Sentiment by star rating\n",
    "sentiment_by_stars = sentiment_df.groupby('stars')['normalized_sentiment_score'].mean()\n",
    "sentiment_by_stars.plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Average Sentiment by Star Rating')\n",
    "axes[0,1].set_xlabel('Stars')\n",
    "axes[0,1].set_ylabel('Average Sentiment Score')\n",
    "\n",
    "# Sentiment vs stars scatter\n",
    "axes[0,2].scatter(sentiment_df['stars'], sentiment_df['normalized_sentiment_score'], alpha=0.1)\n",
    "axes[0,2].set_title('Sentiment Score vs Star Rating')\n",
    "axes[0,2].set_xlabel('Stars')\n",
    "axes[0,2].set_ylabel('Sentiment Score')\n",
    "\n",
    "# Text length vs sentiment\n",
    "text_lengths = sentiment_df['text'].str.len()\n",
    "axes[1,0].scatter(text_lengths, sentiment_df['normalized_sentiment_score'], alpha=0.1)\n",
    "axes[1,0].set_title('Text Length vs Sentiment Score')\n",
    "axes[1,0].set_xlabel('Text Length')\n",
    "axes[1,0].set_ylabel('Sentiment Score')\n",
    "\n",
    "# Sentiment label distribution\n",
    "sentiment_df['sentiment_label'].value_counts().plot(kind='pie', ax=axes[1,1], autopct='%1.1f%%')\n",
    "axes[1,1].set_title('Sentiment Label Distribution')\n",
    "\n",
    "# Correlation between sentiment and stars\n",
    "corr_sentiment_stars = sentiment_df[['stars', 'normalized_sentiment_score']].corr()\n",
    "sns.heatmap(corr_sentiment_stars, annot=True, cmap='coolwarm', ax=axes[1,2])\n",
    "axes[1,2].set_title('Correlation: Stars vs Sentiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Feature Selection\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand feature selection techniques\n",
    "- Learn about best subset selection\n",
    "- Evaluate feature importance\n",
    "- Compare model performance with different feature sets\n",
    "\n",
    "### What We'll Do\n",
    "1. **Data Preparation**: Select candidate features and target\n",
    "2. **Best Subset Selection**: Exhaustive search for optimal feature combinations\n",
    "3. **Model Evaluation**: Compare performance across different feature sets\n",
    "4. **Final Selection**: Choose the best performing feature subset\n",
    "\n",
    "Feature selection identifies the most predictive variables, reducing dimensionality and improving model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature selection pipeline\n",
    "print(\"Starting feature selection pipeline...\")\n",
    "print(\"This involves exhaustive search over feature combinations.\")\n",
    "print(\"Processing time depends on the number of candidate features.\")\n",
    "\n",
    "try:\n",
    "    final_df, optimal_features = feature_selection_pipeline(sentiment_df)\n",
    "    print(\"\\n✓ Feature selection completed successfully!\")\n",
    "    \n",
    "    print(f\"\\nSelected {len(optimal_features)} optimal features:\")\n",
    "    for i, feature in enumerate(optimal_features, 1):\n",
    "        print(f\"{i}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during feature selection: {e}\")\n",
    "    print(\"Please check the previous steps and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final dataset\n",
    "print(\"Final Dataset Overview:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Shape: {final_df.shape}\")\n",
    "print(f\"Features: {list(final_df.columns)}\")\n",
    "\n",
    "display(final_df.head())\n",
    "\n",
    "# Statistics for final features\n",
    "print(\"\\nFinal Feature Statistics:\")\n",
    "display(final_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Model Training and Evaluation\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand neural network training\n",
    "- Learn about stratified sampling and cross-validation\n",
    "- Evaluate regression model performance\n",
    "- Interpret training metrics and learning curves\n",
    "\n",
    "### What We'll Do\n",
    "1. **Data Preparation**: Stratify and split data\n",
    "2. **Model Architecture**: Initialize PyTorch neural network\n",
    "3. **Training**: Train with early stopping and validation\n",
    "4. **Evaluation**: Assess performance on test set\n",
    "5. **Visualization**: Plot training progress and predictions\n",
    "\n",
    "We'll train a neural network to predict star ratings from our engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training pipeline\n",
    "print(\"Starting model training pipeline...\")\n",
    "print(\"This will train a neural network for star rating prediction.\")\n",
    "\n",
    "try:\n",
    "    training_results = training_pipeline()\n",
    "    print(\"\\n✓ Model training completed successfully!\")\n",
    "    \n",
    "    # Display results\n",
    "    metrics = training_results['metrics']\n",
    "    print(\"\\nTraining Results:\")\n",
    "    print(f\"MSE: {metrics['mse']:.4f}\")\n",
    "    print(f\"MAE: {metrics['mae']:.4f}\")\n",
    "    print(f\"R²: {metrics['r2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nModel saved to: {training_results['model_path']}\")\n",
    "    print(f\"Scaler saved to: {training_results['scaler_path']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during training: {e}\")\n",
    "    print(\"Please check the previous steps and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Inference and Predictions\n",
    "\n",
    "### Learning Objectives\n",
    "- Learn model loading and inference\n",
    "- Understand prediction preprocessing\n",
    "- Create custom prediction examples\n",
    "- Interpret model outputs\n",
    "\n",
    "### What We'll Do\n",
    "1. **Model Loading**: Load trained model and scaler\n",
    "2. **Example Creation**: Build prediction examples\n",
    "3. **Inference**: Make predictions on new data\n",
    "4. **Interpretation**: Understand prediction results\n",
    "\n",
    "Now let's use our trained model to make predictions on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and scaler for inference\n",
    "import torch\n",
    "import pickle\n",
    "from src.model import YelpRatingPredictor\n",
    "\n",
    "try:\n",
    "    # Load model\n",
    "    model = YelpRatingPredictor(input_size=len(optimal_features))\n",
    "    model.load_state_dict(torch.load(training_results['model_path'], map_location='cpu'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Load scaler\n",
    "    with open(training_results['scaler_path'], 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    print(\"✓ Model and scaler loaded successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading model: {e}\")\n",
    "    print(\"Please ensure training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction examples\n",
    "examples = [\n",
    "    {\n",
    "        'user_average_stars': 4.5,\n",
    "        'business_average_stars': 4.2,\n",
    "        'time_yelping': 100.0,\n",
    "        'elite_status': 1,\n",
    "        'normalized_sentiment_score': 0.8\n",
    "    },\n",
    "    {\n",
    "        'user_average_stars': 3.0,\n",
    "        'business_average_stars': 3.5,\n",
    "        'time_yelping': 25.0,\n",
    "        'elite_status': 0,\n",
    "        'normalized_sentiment_score': -0.3\n",
    "    },\n",
    "    {\n",
    "        'user_average_stars': 4.0,\n",
    "        'business_average_stars': 4.8,\n",
    "        'time_yelping': 200.0,\n",
    "        'elite_status': 1,\n",
    "        'normalized_sentiment_score': 0.9\n",
    "    }\n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "for i, example in enumerate(examples, 1):\n",
    "    # Filter to optimal features\n",
    "    filtered_input = {k: v for k, v in example.items() if k in optimal_features}\n",
    "    input_df = pd.DataFrame([filtered_input])\n",
    "    \n",
    "    # Scale input\n",
    "    scaled_input = scaler.transform(input_df.values)\n",
    "    input_tensor = torch.FloatTensor(scaled_input)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor).item()\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    print(f\"Example {i}: Predicted rating = {prediction:.2f}\")\n",
    "    print(f\"  Input: {filtered_input}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Analysis and Insights\n",
    "\n",
    "### Learning Objectives\n",
    "- Analyze model performance in depth\n",
    "- Understand feature contributions\n",
    "- Identify model limitations\n",
    "- Explore what-if scenarios\n",
    "\n",
    "### What We'll Do\n",
    "1. **Performance Analysis**: Deep dive into metrics\n",
    "2. **Error Analysis**: Understand prediction errors\n",
    "3. **Feature Importance**: Analyze which features matter most\n",
    "4. **Limitations**: Discuss model assumptions and constraints\n",
    "5. **Future Work**: Suggest improvements\n",
    "\n",
    "Let's analyze our model's behavior and performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data for analysis\n",
    "try:\n",
    "    # Load the stratified data used for training\n",
    "    stratified_df = pd.read_csv('data/processed/final_model_data.csv')\n",
    "    \n",
    "    # Load optimal features\n",
    "    with open('data/processed/optimal_features.json', 'r') as f:\n",
    "        optimal_features = json.load(f)\n",
    "    \n",
    "    print(\"✓ Analysis data loaded successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading analysis data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis\n",
    "print(\"Model Performance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean Squared Error (MSE): {metrics['mse']:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {metrics['mae']:.4f}\")\n",
    "print(f\"R² Score: {metrics['r2']:.4f}\")\n",
    "print(f\"RMSE: {metrics['mse']**0.5:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "if metrics['r2'] > 0.7:\n",
    "    print(\"✓ Excellent performance (R² > 0.7)\")\n",
    "elif metrics['r2'] > 0.5:\n",
    "    print(\"✓ Good performance (R² > 0.5)\")\n",
    "elif metrics['r2'] > 0.3:\n",
    "    print(\"✓ Moderate performance (R² > 0.3)\")\n",
    "else:\n",
    "    print(\"⚠ Limited performance - consider feature engineering or model improvements\")\n",
    "\n",
    "print(f\"\\nOn average, predictions are off by {metrics['mae']:.2f} stars.\")\n",
    "print(f\"Typical prediction error range: ±{metrics['mae']*1.96:.2f} stars (95% confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "print(\"\\nFeature Analysis:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Selected optimal features ({len(optimal_features)}):\")\n",
    "for i, feature in enumerate(optimal_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "# Correlation analysis\n",
    "feature_corrs = stratified_df[optimal_features + ['stars']].corr()['stars'].abs().sort_values(ascending=False)\n",
    "print(\"\\nFeature correlations with target:\")\n",
    "for feature in optimal_features:\n",
    "    corr = feature_corrs[feature]\n",
    "    print(f\"{feature:25s}: {corr:.4f}\")\n",
    "\n",
    "# Visualize feature correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_corrs[optimal_features].sort_values().plot(kind='barh')\n",
    "plt.title('Feature Correlations with Star Rating')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model limitations and insights\n",
    "print(\"\\nModel Limitations and Insights:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"1. **Data Scope**: Model trained on Yelp Academic Dataset only\")\n",
    "print(\"2. **Feature Limitations**: Predictions based on available user/business features\")\n",
    "print(\"3. **Sentiment Context**: Text analysis may miss nuanced sentiment\")\n",
    "print(\"4. **Temporal Factors**: Model doesn't account for trends over time\")\n",
    "print(\"5. **Geographic Bias**: Results may not generalize to all locations\")\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"• User history (average stars, elite status) strongly predicts ratings\")\n",
    "print(\"• Business quality is a major factor\")\n",
    "print(\"• Experience level (time yelping) influences rating patterns\")\n",
    "print(\"• Review sentiment provides additional predictive power\")\n",
    "\n",
    "print(\"\\nFuture Improvements:\")\n",
    "print(\"• Incorporate temporal trends and seasonality\")\n",
    "print(\"• Add geographic and demographic features\")\n",
    "print(\"• Use more advanced NLP models for sentiment\")\n",
    "print(\"• Implement ensemble methods for better performance\")\n",
    "print(\"• Add uncertainty quantification to predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've successfully completed the interactive Yelp rating prediction pipeline. Here's what we accomplished:\n",
    "\n",
    "### Pipeline Stages Completed:\n",
    "1. ✅ **Data Loading & Preprocessing**: Loaded and cleaned Yelp dataset\n",
    "2. ✅ **Feature Engineering**: Created time-based and elite status features\n",
    "3. ✅ **Sentiment Analysis**: Extracted sentiment scores from review text\n",
    "4. ✅ **Feature Selection**: Identified optimal feature subset\n",
    "5. ✅ **Model Training**: Trained neural network for rating prediction\n",
    "6. ✅ **Inference**: Demonstrated model predictions\n",
    "7. ✅ **Analysis**: Explored model performance and insights\n",
    "\n",
    "### Key Learnings:\n",
    "- **Data preprocessing** is crucial for model performance\n",
    "- **Feature engineering** transforms raw data into predictive features\n",
    "- **Sentiment analysis** adds valuable text-derived insights\n",
    "- **Feature selection** improves model efficiency and interpretability\n",
    "- **Neural networks** can effectively model complex relationships\n",
    "\n",
    "### Model Performance:\n",
    "- **MSE**: {metrics['mse']:.4f}\n",
    "- **MAE**: {metrics['mae']:.4f}\n",
    "- **R²**: {metrics['r2']:.4f}\n",
    "\n",
    "### Files Created:\n",
    "- `data/processed/merged_data.csv`: Preprocessed dataset\n",
    "- `data/processed/featured_data.csv`: Engineered features\n",
    "- `data/processed/sentiment_data.csv`: With sentiment scores\n",
    "- `data/processed/final_model_data.csv`: Final training data\n",
    "- `models/best_model.pt`: Trained PyTorch model\n",
    "- `models/scaler.pkl`: Feature scaler\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline from raw data to production-ready model. You can now apply these techniques to other prediction problems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}